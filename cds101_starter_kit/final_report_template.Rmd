---
title: "CDS 101 â€“ Final Project Report"
author: "Ankith Kolapalli, Julia Conway, Ruhama"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    css: "gmu-cds101.css"
    toc: true
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: true
---

> Replace this template text with your own writing, keeping the headings and overall structure aligned with the **CDS 101 project rubric**.

# 1. Problem Definition

- Clearly state the main problem or question you are investigating.  
- Explain why it is interesting or important.  
- Define the objective(s) of your analysis.  
- Mention any key assumptions.

# 2. Data Acquisition & Description

Data Set Name: CarDekho Vehicle Dataset
Source: Kaggle (https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho)
Variable description: the dataset has car features like brand, body type, engine type, distance, registration, and price.  
Size: around 4,300 rows with 9 coloumns  


```{r}
library(readr)
library(dplyr)
library(ggplot2)
cars_raw <- read_csv("data/cars_data.csv")
```

# 3. Data Cleaning & Preprocessing

Describe the steps you took to make the data usable, for example:

- Handling missing values (drop, impute, etc.).  
- Fixing types (dates, numeric vs. categorical).  
- Removing outliers (if done).  
- Creating new features (feature engineering).  
- Any scaling or encoding.

```{r cleaning, eval=FALSE}
# Example pseudo-code for cleaning:
# data_clean <- data |>
#   dplyr::filter(!is.na(target_variable)) |>
#   dplyr::mutate(
#     new_feature = some_transformation(old_feature)
#   )
```

```{r}
cars_clean <- cars_raw %>%
  filter(!is.na(Price), !is.na(Brand)) %>% 
  rename(EngineType = `Engine Type`) %>% 
  mutate(Brand = factor(Brand),
         Body = factor(Body),
         EngineType = factor(EngineType),
         Registration = factor(Registration)
  )
```

# 4. Exploratory Data Analysis (EDA)

This section maps directly to the **EDA** part of the rubric:

- Summary statistics  
- Visualizations  
- Interpretation connected to the research question  

```{r}
library(dplyr)
summary(cars_data)
```


```{r}
ggplot(cars_clean, aes(x = Price)) +
  geom_histogram(binwidth = 5000, color = "black", fill = "blue") +
  coord_cartesian(xlim = c(0, 40000))
  labs(title = "Histogram of Used Car Prices",
       x = "Price",
       y = "Count"
  )
```


```{r}
ggplot(cars_clean, aes(x = Mileage)) +
  geom_histogram(binwidth = 18, color = "black", fill = "green") +
  labs(title = "Histogram of Car Mileage",
       x = "Mileage",
       y = "Count")
```
```{r}
avg_price<- cars_clean %>%
  group_by(Brand) %>%
  summarise(mean_price = mean(Price, na.rm = TRUE)) %>%
  arrange(mean_price)

ggplot(avg_price,aes(x = reorder(Brand, mean_price), y = mean_price)) +
  geom_col(fill = "pink") +
  coord_flip() +
  labs(title = "Average Used Car Price by Brand",
       x = "Brand",
       y = "Average Price")
```
```{r}
ggplot(cars_clean, aes(x = Mileage, y = Price)) +
  geom_point(alpha = 0.4) +
  labs(
    title = "Relationship Between Mileage and Price",
    x = "Mileage",
    y = "Price"
  )
```
# 5. Visualization Quality and Storytelling

Use this section to satisfy the **Visualization Quality** rubric criterion:

- Explain why your plot types are appropriate.  
- Comment on labels, legends, colors, and overall readability.  
- Mention any steps you took to make plots accessible and interpretable.

# 6. Modeling Approach

Explain how you framed the problem and which models you chose:

- Type of task (regression, classification, etc.).  
- Baseline model or heuristic, if used.  
- Main model(s) chosen and why they are appropriate.

# 7. Model Implementation & Evaluation

This corresponds to the **Model Implementation & Evaluation** rubric criterion.

Describe:

- Features used.  
- Data splitting strategy (train/test or cross-validation).  
- Metrics used (accuracy, F1, RMSE, etc.).  
- Tables/plots summarizing performance.  
- A short interpretation of each metric/plot.

```{r modeling, eval=FALSE}
# Example structure:
# set.seed(123)
# train_index <- sample(seq_len(nrow(data_clean)), size = 0.8 * nrow(data_clean))
# train <- data_clean[train_index, ]
# test  <- data_clean[-train_index, ]
#
# model <- glm(target ~ ., data = train, family = binomial)
# preds <- predict(model, newdata = test, type = "response")
# # compute metrics...
```

# 8. Conclusions & Recommendations

Summarize the key takeaways:

- Answer your original research question(s) directly.  
- Highlight the most important patterns or relationships you found.  
- Discuss limitations (data size, bias, missing variables, etc.).  
- Suggest possible extensions or future work.

# 9. Code Quality & Reproducibility

Briefly document how someone else can reproduce your results:

- Which R scripts or Rmd files to run.  
- Any required R packages.  

```{r session-info, echo=FALSE}
sessionInfo()
```

# 10. References

List any references you used, such as:

- Dataset documentation.  
- Research papers or articles.  
- Tutorials or blog posts.

# Appendix (Optional)

Include extra plots, diagnostic checks, or model comparisons if needed.
